{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-back EEG — Minimal Pipeline\n",
    "**What it does:** Load XDF → (optional) preprocess → align markers → infer block difficulties → write session marker + 5s difficulty segments → (optional) build epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDF: ..\\..\\data\\sub-P001_jannik\\ses-S001\\eeg\\sub-P001_ses-S001_task-Default_run-001_eeg.xdf \n",
      "CSV: ..\\..\\data\\sub-P001_jannik\\ses-S001\\marker_log_p1s1_Jannik.csv \n",
      "Extractor: ..\\Block_difficulty_extractor.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys, re, importlib.util\n",
    "# Helper\n",
    "def R(name: str) -> Path:\n",
    "    return RESULTS_DIR / name\n",
    "\n",
    "# --- SETTINGS --------------------------------------------------------------\n",
    "XDF_PATH     = Path(r\"../../data/sub-P001_jannik/ses-S001/eeg/sub-P001_ses-S001_task-Default_run-001_eeg.xdf\")\n",
    "MARKERS_CSV  = Path(r\"../../data/sub-P001_jannik/ses-S001/marker_log_p1s1_Jannik.csv\")\n",
    "BDE_PATH     = Path(r\"../Block_difficulty_extractor.py\")     # provides calculate_nvals(df)\n",
    "PREPROC_MOD  = Path(r\"../preprocess_raw.py\")                 # optional; if present, will be used\n",
    "\n",
    "DO_PREPROCESS = True      # set False to skip preprocess_raw\n",
    "DO_EPOCHS     = True      # set False if you only want annotations\n",
    "\n",
    "# Outputs\n",
    "OUT_BASENAME = Path(r\"../results\").with_suffix(\"\").name\n",
    "\n",
    "# Where to save everything\n",
    "RESULTS_DIR = (XDF_PATH.parent / \"results\").resolve()\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_BASENAME = XDF_PATH.with_suffix(\"\").name\n",
    "\n",
    "RAW_FIF = R(f\"{OUT_BASENAME}_raw.fif\")                # (if you ever save raw)\n",
    "EPO_FIF = R(f\"{OUT_BASENAME}_segments-epo.fif\")       # 5s segments epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"XDF:\", XDF_PATH, \"\\nCSV:\", MARKERS_CSV, \"\\nExtractor:\", BDE_PATH)\n",
    "assert XDF_PATH.exists() and MARKERS_CSV.exists() and BDE_PATH.exists(), \"One of the input files is missing.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocess_raw from: ..\\preprocess_raw.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np, pandas as pd, mne, pyxdf\n",
    "\n",
    "# Optional preprocessing module\n",
    "preprocess_raw = None\n",
    "if PREPROC_MOD.exists():\n",
    "    spec = importlib.util.spec_from_file_location(\"preprocess_raw\", str(PREPROC_MOD))\n",
    "    preprocess_raw = importlib.util.module_from_spec(spec); spec.loader.exec_module(preprocess_raw)\n",
    "    print(\"Loaded preprocess_raw from:\", PREPROC_MOD)\n",
    "\n",
    "# Block difficulty extractor\n",
    "spec = importlib.util.spec_from_file_location(\"bde\", str(BDE_PATH))\n",
    "bde = importlib.util.module_from_spec(spec); sys.modules[\"bde\"] = bde; spec.loader.exec_module(bde)\n",
    "assert hasattr(bde, \"calculate_nvals\") and callable(bde.calculate_nvals), \"Extractor must expose calculate_nvals(df).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawArray | 17 x 397344 (1589.4 s), ~51.6 MiB, data loaded>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "streams, header = pyxdf.load_xdf(str(XDF_PATH))\n",
    "\n",
    "def _is_numeric(s): \n",
    "    ts = np.asarray(s.get(\"time_series\")); return np.issubdtype(ts.dtype, np.number)\n",
    "def _nchan(s):\n",
    "    try:\n",
    "        desc = s[\"info\"].get(\"desc\", [None])[0]\n",
    "        return len(desc[\"channels\"][0][\"channel\"]) if desc and \"channels\" in desc and desc[\"channels\"] else 1\n",
    "    except Exception:\n",
    "        ts = np.asarray(s.get(\"time_series\"), dtype=object)\n",
    "        return 1 if ts.ndim==1 else ts.shape[1]\n",
    "def _srate(s): \n",
    "    try: return float(s[\"info\"][\"nominal_srate\"][0])\n",
    "    except: return 0.0\n",
    "\n",
    "eeg = [s for s in streams if s[\"info\"].get(\"type\",[\"\"])[0].upper()==\"EEG\" and _is_numeric(s)]\n",
    "if not eeg: eeg = [s for s in streams if _is_numeric(s) and _srate(s)>0 and _nchan(s)>=4]\n",
    "if not eeg: eeg = [s for s in streams if _is_numeric(s)]\n",
    "eeg = sorted(eeg, key=lambda s: (_nchan(s), _srate(s)), reverse=True)\n",
    "eeg_stream = eeg[0]\n",
    "\n",
    "data = np.asarray(eeg_stream[\"time_series\"]); \n",
    "if data.ndim==1: data = data[:,None]\n",
    "data = data.T\n",
    "sfreq = _srate(eeg_stream)\n",
    "if sfreq<=0:\n",
    "    ts = np.asarray(eeg_stream.get(\"time_stamps\")); sfreq = 1.0/np.median(np.diff(ts))\n",
    "\n",
    "try:\n",
    "    chs = [c[\"label\"][0] for c in eeg_stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]]\n",
    "    if len(chs)!=data.shape[0]: raise ValueError\n",
    "except Exception:\n",
    "    chs = [f\"EEG{i+1}\" for i in range(data.shape[0])]\n",
    "\n",
    "info = mne.create_info(chs, sfreq=sfreq, ch_types=\"eeg\")\n",
    "raw  = mne.io.RawArray(data, info, verbose=False)\n",
    "try: raw.set_montage(\"standard_1020\", on_missing=\"ignore\")\n",
    "except: pass\n",
    "print(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-12 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-12 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 8251 samples (33.004 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Sampling frequency of the instance is already 250.0, returning unmodified.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Fitting ICA to data using 17 channels (please be patient, this may take a while)\n",
      "Selecting by explained variance: 2 components\n",
      "Fitting ICA took 1.5s.\n",
      "Overwriting existing file.\n",
      "Writing ICA solution to c:\\Users\\janni\\Documents\\GitHub\\eeg-brain-interface\\scripts\\notebooks\\sub-P001_ses-S001_task-Default_run-001_eeg-ica.fif...\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Writing c:\\Users\\janni\\Documents\\GitHub\\eeg-brain-interface\\scripts\\notebooks\\sub-P001_ses-S001_task-Default_run-001_eeg_preproc_raw.fif\n",
      "Overwriting existing file.\n",
      "Closing c:\\Users\\janni\\Documents\\GitHub\\eeg-brain-interface\\scripts\\notebooks\\sub-P001_ses-S001_task-Default_run-001_eeg_preproc_raw.fif\n",
      "[done]\n",
      "ICA excluded: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if DO_PREPROCESS and preprocess_raw is not None:\n",
    "    cfg = preprocess_raw.default_config()\n",
    "    cfg[\"save_base\"] = OUT_BASENAME\n",
    "    raw, ica, rep = preprocess_raw.preprocess_raw(raw, cfg)\n",
    "    print(\"ICA excluded:\", rep[\"exclude\"])\n",
    "else:\n",
    "    print(\"Skipping preprocess (set DO_PREPROCESS=True and provide preprocess_raw.py to enable).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   block_idx  n\n",
      "0          0  0\n",
      "1          1  3\n",
      "2          2  1\n",
      "3          3  2\n",
      "4          4  2\n",
      "5          5  1\n",
      "6          6  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janni\\AppData\\Local\\Temp\\ipykernel_9720\\1479132835.py:24: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  block_order = df.loc[df[\"marker\"].str.contains(blk_re), \"_block_idx\"].dropna().astype(int).unique().tolist()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(MARKERS_CSV)\n",
    "# normalize names\n",
    "lower = {c.lower(): c for c in df.columns}\n",
    "on_col  = lower.get(\"timestamp\") or lower.get(\"onset\") or lower.get(\"time\")\n",
    "desc_col= lower.get(\"marker\") or lower.get(\"description\") or lower.get(\"event\")\n",
    "assert on_col and desc_col, \"CSV must have a time (timestamp/onset) and a marker/description column.\"\n",
    "df = df.rename(columns={on_col:\"timestamp\", desc_col:\"marker\"})\n",
    "df[\"marker\"] = df[\"marker\"].astype(str).str.strip()\n",
    "\n",
    "# Align timestamps to Raw start\n",
    "eeg_ts = np.asarray(eeg_stream.get(\"time_stamps\"), dtype=float); t0 = float(eeg_ts[0]); raw_dur = float(raw.times[-1])\n",
    "on = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "rel = on - t0\n",
    "if np.nanmax(rel) > raw_dur*10: rel = rel/1000.0 - (t0)  # naive ms guard\n",
    "df[\"timestamp\"] = rel\n",
    "\n",
    "# Detect block starts -> forward-fill block_idx\n",
    "blk_re = re.compile(r\"(?i)\\b(?:practice|main)_block_(\\d+)_start\\b\")\n",
    "starts = df[\"marker\"].str.extract(blk_re)[0]\n",
    "df[\"_block_idx\"] = pd.to_numeric(starts, errors=\"coerce\").ffill()\n",
    "\n",
    "# Infer difficulties per block using your extractor\n",
    "levels = bde.calculate_nvals(df[[\"marker\",\"timestamp\"]].copy())\n",
    "block_order = df.loc[df[\"marker\"].str.contains(blk_re), \"_block_idx\"].dropna().astype(int).unique().tolist()\n",
    "# align\n",
    "k = min(len(levels), len(block_order)); levels = list(map(int, levels[:k])); block_order = block_order[:k]\n",
    "blocks_df = pd.DataFrame({\"block_idx\": block_order, \"n\": levels})\n",
    "print(blocks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session: lab_noise | segments: 266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Session marker from path\n",
    "p = str(XDF_PATH)\n",
    "session_label = \"lab_noise\" if re.search(r\"ses[-_]?S001\", p, flags=re.I) else (\"gw2_noise\" if re.search(r\"ses[-_]?S002\", p, flags=re.I) else \"noise_unknown\")\n",
    "\n",
    "# Block time ranges from df\n",
    "blk_times = (df.dropna(subset=[\"_block_idx\"])\n",
    "               .groupby(\"_block_idx\")[\"timestamp\"]\n",
    "               .agg([\"min\",\"max\"]).reset_index()\n",
    "               .rename(columns={\"_block_idx\":\"block_idx\",\"min\":\"t_start\",\"max\":\"t_end\"}))\n",
    "\n",
    "blk = blk_times.merge(blocks_df, on=\"block_idx\", how=\"inner\").sort_values(\"block_idx\")\n",
    "\n",
    "# Build 5s segments\n",
    "seg_on, seg_dur, seg_desc = [], [], []\n",
    "for _, r in blk.iterrows():\n",
    "    n = int(r[\"n\"]); t0 = max(float(r[\"t_start\"]), 0.0); t1 = min(float(r[\"t_end\"]), float(raw.times[-1]))\n",
    "    t = t0\n",
    "    while t < t1:\n",
    "        t2 = min(t+5.0, t1)\n",
    "        seg_on.append(t); seg_dur.append(t2-t); seg_desc.append(f\"difficulty/{n}-back\")\n",
    "        t = t2\n",
    "\n",
    "sess_ann = mne.Annotations(onset=[0.0], duration=[float(raw.times[-1])], description=[session_label], orig_time=None)\n",
    "seg_ann  = mne.Annotations(onset=np.array(seg_on), duration=np.array(seg_dur), description=seg_desc, orig_time=None)\n",
    "\n",
    "raw.set_annotations(sess_ann + seg_ann)\n",
    "print(\"Session:\", session_label, \"| segments:\", len(seg_ann))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('difficulty/0-back'), np.str_('difficulty/1-back'), np.str_('difficulty/2-back'), np.str_('difficulty/3-back')]\n",
      "Not setting metadata\n",
      "266 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 266 events and 1251 original time points ...\n",
      "0 bad epochs dropped\n",
      "Adding metadata with 1 columns\n",
      "<Epochs | 266 events (all good), 0 – 5 s (baseline off), ~43.2 MiB, data loaded, with metadata,\n",
      " np.str_('difficulty/0-back'): 28\n",
      " np.str_('difficulty/1-back'): 84\n",
      " np.str_('difficulty/2-back'): 84\n",
      " np.str_('difficulty/3-back'): 70>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if DO_EPOCHS:\n",
    "    desc = np.asarray(raw.annotations.description, dtype=str)\n",
    "    present_n = sorted({int(d.split(\"/\")[1].split(\"-\")[0]) for d in desc if d.startswith(\"difficulty/\")})\n",
    "    event_id = {f\"difficulty/{n}-back\": 10+n for n in present_n}\n",
    "    events, eid_used = mne.events_from_annotations(raw, event_id=event_id)\n",
    "    epochs = mne.Epochs(raw, events, event_id=eid_used, tmin=0.0, tmax=5.0,\n",
    "                        baseline=None, preload=True, reject_by_annotation=False)\n",
    "    epochs.metadata = pd.DataFrame({\"difficulty\":[int([k for k,v in eid_used.items() if v==c][0].split('/')[1].split('-')[0]) for c in epochs.events[:,2]]})\n",
    "    print(epochs)\n",
    "    epochs.save(EPO_FIF, overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping epochs (set DO_EPOCHS=True to build).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML (Random Forest): bandpower features → predict n-back\n",
    "This cell extracts **bandpower features** per epoch (delta/theta/alpha/beta/gamma per channel) using Welch PSD, and trains a **RandomForestClassifier**. It reports stratified 5-fold CV accuracy, a confusion matrix, and top feature importances. If `epochs` isn't in memory, it loads `EPO_FIF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 channels: ['EEG1', 'EEG2', 'EEG3', 'EEG4', 'EEG5', 'EEG6', 'EEG7', 'EEG8']\n",
      "<Epochs | 266 events (all good), 0 – 5 s (baseline off), ~20.3 MiB, data loaded, with metadata,\n",
      " np.str_('difficulty/0-back'): 28\n",
      " np.str_('difficulty/1-back'): 84\n",
      " np.str_('difficulty/2-back'): 84\n",
      " np.str_('difficulty/3-back'): 70>\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature matrix: (266, 40) | labels: (266,)\n",
      "RF CV accuracy: [0.537 0.585 0.604 0.623 0.66 ]  | mean±sd: 0.602 ± 0.041\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.611     0.393     0.478        28\n",
      "           1      0.573     0.655     0.611        84\n",
      "           2      0.701     0.560     0.623        84\n",
      "           3      0.553     0.671     0.606        70\n",
      "\n",
      "    accuracy                          0.602       266\n",
      "   macro avg      0.610     0.570     0.580       266\n",
      "weighted avg      0.612     0.602     0.600       266\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[11  5  2 10]\n",
      " [ 1 55 13 15]\n",
      " [ 4 20 47 13]\n",
      " [ 2 16  5 47]]\n",
      "Majority-class baseline: 0.316 (label=1)\n",
      "\n",
      "Top 20 features by importance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EEG2_gamma</td>\n",
       "      <td>0.042043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EEG6_gamma</td>\n",
       "      <td>0.041490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EEG1_alpha</td>\n",
       "      <td>0.037714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EEG8_gamma</td>\n",
       "      <td>0.037671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EEG8_beta</td>\n",
       "      <td>0.032220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EEG8_theta</td>\n",
       "      <td>0.031024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EEG2_theta</td>\n",
       "      <td>0.030745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EEG2_beta</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EEG6_theta</td>\n",
       "      <td>0.030532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EEG7_theta</td>\n",
       "      <td>0.030349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEG1_beta</td>\n",
       "      <td>0.029632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EEG7_gamma</td>\n",
       "      <td>0.029606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EEG3_gamma</td>\n",
       "      <td>0.028148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EEG4_theta</td>\n",
       "      <td>0.027529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EEG7_alpha</td>\n",
       "      <td>0.026745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EEG8_alpha</td>\n",
       "      <td>0.024927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EEG5_gamma</td>\n",
       "      <td>0.024661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EEG4_delta</td>\n",
       "      <td>0.024541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EEG7_beta</td>\n",
       "      <td>0.024478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EEG6_alpha</td>\n",
       "      <td>0.024150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0   EEG2_gamma    0.042043\n",
       "1   EEG6_gamma    0.041490\n",
       "2   EEG1_alpha    0.037714\n",
       "3   EEG8_gamma    0.037671\n",
       "4    EEG8_beta    0.032220\n",
       "5   EEG8_theta    0.031024\n",
       "6   EEG2_theta    0.030745\n",
       "7    EEG2_beta    0.030556\n",
       "8   EEG6_theta    0.030532\n",
       "9   EEG7_theta    0.030349\n",
       "10   EEG1_beta    0.029632\n",
       "11  EEG7_gamma    0.029606\n",
       "12  EEG3_gamma    0.028148\n",
       "13  EEG4_theta    0.027529\n",
       "14  EEG7_alpha    0.026745\n",
       "15  EEG8_alpha    0.024927\n",
       "16  EEG5_gamma    0.024661\n",
       "17  EEG4_delta    0.024541\n",
       "18   EEG7_beta    0.024478\n",
       "19  EEG6_alpha    0.024150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: C:\\Users\\janni\\Documents\\GitHub\\eeg-brain-interface\\data\\sub-P001_jannik\\ses-S001\\eeg\\results\\sub-P001_ses-S001_task-Default_run-001_eeg_rf_bandpower.joblib\n",
      "Saved features to: C:\\Users\\janni\\Documents\\GitHub\\eeg-brain-interface\\data\\sub-P001_jannik\\ses-S001\\eeg\\results\\sub-P001_ses-S001_task-Default_run-001_eeg_rf_bandpower.features.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Random Forest on bandpower features ---\n",
    "import numpy as np, pandas as pd, mne, joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Keep only the first 8 channels for decoding\n",
    "N = min(8, len(epochs.ch_names))\n",
    "picks8 = epochs.ch_names[:N]\n",
    "ep8 = epochs.copy().pick(picks=picks8)\n",
    "print(f\"Using {N} channels:\", picks8)\n",
    "\n",
    "epochs = ep8  # use only these channels\n",
    "\n",
    "\n",
    "# 1) Load epochs if needed\n",
    "if \"epochs\" not in globals():\n",
    "    assert 'EPO_FIF' in globals(), \"EPO_FIF path missing; run epoching or set EPO_FIF.\"\n",
    "    print(\"Loading epochs from:\", EPO_FIF)\n",
    "    epochs = mne.read_epochs(EPO_FIF, preload=True)\n",
    "\n",
    "assert epochs.metadata is not None and \"difficulty\" in epochs.metadata.columns, \"epochs.metadata must contain 'difficulty'.\"\n",
    "print(epochs)\n",
    "\n",
    "# 2) Filter for stable bandpowers\n",
    "ep_filt = epochs.copy().filter(1., 40., picks=\"eeg\")\n",
    "\n",
    "# 3) PSD per epoch (new API first; fallback to old if needed)\n",
    "try:\n",
    "    # MNE >= 1.2 style\n",
    "    psd = ep_filt.compute_psd(\n",
    "        method=\"welch\",\n",
    "        fmin=1., fmax=40.,\n",
    "        n_fft=int(ep_filt.info['sfreq'] * 2),\n",
    "        n_overlap=int(ep_filt.info['sfreq'] * 1),\n",
    "        picks=\"eeg\",\n",
    "        verbose=False\n",
    "    )\n",
    "    psds, freqs = psd.get_data(return_freqs=True)  # (n_epochs, n_channels, n_freqs)\n",
    "except Exception:\n",
    "    # Older MNE fallback (only if your env still has it)\n",
    "    from mne.time_frequency import psd_welch\n",
    "    psds, freqs = psd_welch(\n",
    "        ep_filt, fmin=1., fmax=40.,\n",
    "        n_fft=int(ep_filt.info['sfreq'] * 2),\n",
    "        n_overlap=int(ep_filt.info['sfreq'] * 1),\n",
    "        picks=\"eeg\", average=\"mean\", n_per_seg=None, verbose=False\n",
    "    )\n",
    "\n",
    "\n",
    "# 4) Band definitions and integration\n",
    "bands = {\"delta\": (1, 4), \"theta\": (4, 8), \"alpha\": (8, 13), \"beta\": (13, 30), \"gamma\": (30, 40)}\n",
    "bin_mask = {b: (freqs >= lo) & (freqs < hi) for b, (lo, hi) in bands.items()}\n",
    "total_pow = psds.sum(axis=2) + 1e-12  # avoid div by zero\n",
    "\n",
    "# Build feature matrix: relative bandpower per channel\n",
    "feat_list = []\n",
    "col_names = []\n",
    "for bi, (b, m) in enumerate(bin_mask.items()):\n",
    "    bp = psds[:, :, m].sum(axis=2)  # (n_epochs, n_channels)\n",
    "    rel = bp / total_pow\n",
    "    feat_list.append(rel)\n",
    "    col_names += [f\"{ch}_{b}\" for ch in ep_filt.ch_names]\n",
    "X = np.concatenate(feat_list, axis=1)   # shape: (n_epochs, n_channels * n_bands)\n",
    "y = ep_filt.metadata[\"difficulty\"].astype(int).to_numpy()\n",
    "\n",
    "print(\"Feature matrix:\", X.shape, \"| labels:\", y.shape)\n",
    "\n",
    "# 5) Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "    class_weight=\"balanced_subsample\", random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=min(5, np.bincount(y).min() if len(np.unique(y))>1 else 2),\n",
    "                     shuffle=True, random_state=42)\n",
    "scores = cross_val_score(rf, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"RF CV accuracy:\", np.round(scores, 3), \" | mean±sd:\", f\"{scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "\n",
    "y_pred = cross_val_predict(rf, X, y, cv=cv, n_jobs=-1)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y, y_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=sorted(np.unique(y)))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "maj = np.bincount(y).argmax()\n",
    "print(f\"Majority-class baseline: {(y==maj).mean():.3f} (label={maj})\")\n",
    "\n",
    "# 6) Fit on full data and report top features\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "topk = np.argsort(importances)[::-1][:20]\n",
    "top_table = pd.DataFrame({\n",
    "    \"feature\": [col_names[i] for i in topk],\n",
    "    \"importance\": importances[topk]\n",
    "})\n",
    "print(\"\\nTop 20 features by importance:\")\n",
    "display(top_table)\n",
    "\n",
    "# 7) Save artifacts (optional)\n",
    "MODEL_PATH = EPO_FIF.with_suffix(\"\").with_name(f\"{OUT_BASENAME}_rf_bandpower.joblib\") if 'OUT_BASENAME' in globals() else Path(\"rf_bandpower.joblib\")\n",
    "FEAT_PATH  = MODEL_PATH.with_suffix(\".features.csv\")\n",
    "joblib.dump({\"model\": rf, \"bands\": bands, \"ch_names\": ep_filt.ch_names, \"col_names\": col_names}, MODEL_PATH)\n",
    "pd.DataFrame(X, columns=col_names).assign(y=y).to_csv(FEAT_PATH, index=False)\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "print(\"Saved features to:\", FEAT_PATH)\n",
    "\n",
    "# 8) Helper: function to transform new epochs -> features\n",
    "def extract_bandpower_features(ep: mne.Epochs) -> np.ndarray:\n",
    "    ep2 = ep.copy().filter(1., 40., picks=\"eeg\")\n",
    "    psd, fr = mne.time_frequency.psd_welch(\n",
    "        ep2, fmin=1., fmax=40., n_fft=int(ep2.info['sfreq']*2), n_overlap=int(ep2.info['sfreq']*1),\n",
    "        picks=\"eeg\", average=\"mean\", n_per_seg=None, verbose=False\n",
    "    )\n",
    "    bm = {b: (fr >= lo) & (fr < hi) for b, (lo, hi) in bands.items()}\n",
    "    tp = psd.sum(axis=2) + 1e-12\n",
    "    feats = []\n",
    "    for b, m in bm.items():\n",
    "        bp = psd[:, :, m].sum(axis=2)\n",
    "        rel = bp / tp\n",
    "        feats.append(rel)\n",
    "    return np.concatenate(feats, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ede47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
